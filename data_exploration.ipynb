{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7c7565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             timestamp            user     platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     hashtags  retweets  likes       country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   year  month  day  hour  text_encoded  sentiment_encoded  timestamp_encoded  \\\n",
      "0  2023      1   15    12           105                214                401   \n",
      "1  2023      1   15     8           293                195                400   \n",
      "2  2023      1   15    15           191                214                402   \n",
      "3  2023      1   15    18           120                214                403   \n",
      "4  2023      1   15    19           296                197                405   \n",
      "\n",
      "   user_encoded  platform_encoded  hashtags_encoded  country_encoded  \n",
      "0           645                 3               491              106  \n",
      "1           118                 3               674               20  \n",
      "2           226                 1               309              108  \n",
      "3             7                 0               677               91  \n",
      "4            90                 1               158                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"cleaned_preprocessed_data.csv\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153fdbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   count         mean         std     min      25%     50%  \\\n",
      "retweets           732.0    21.508197    7.061286     5.0    17.75    22.0   \n",
      "likes              732.0    42.901639   14.089848    10.0    34.75    43.0   \n",
      "year               732.0  2020.471311    2.802285  2010.0  2019.00  2021.0   \n",
      "month              732.0     6.122951    3.411763     1.0     3.00     6.0   \n",
      "day                732.0    15.497268    8.474553     1.0     9.00    15.0   \n",
      "hour               732.0    15.521858    4.113414     0.0    13.00    16.0   \n",
      "text_encoded       732.0   348.054645  205.842295     0.0   170.75   344.5   \n",
      "sentiment_encoded  732.0   138.405738   73.735566     0.0    78.00   139.0   \n",
      "timestamp_encoded  732.0   334.312842  195.330508     0.0   167.75   330.0   \n",
      "user_encoded       732.0   343.538251  197.974711     0.0   171.00   343.5   \n",
      "platform_encoded   732.0     1.173497    1.044146     0.0     0.00     1.0   \n",
      "hashtags_encoded   732.0   349.203552  200.283495     0.0   174.75   351.5   \n",
      "country_encoded    732.0    61.122951   38.112422     0.0    20.75    63.5   \n",
      "\n",
      "                       75%     max  median      variance  \n",
      "retweets             25.00    40.0    22.0     49.861766  \n",
      "likes                50.00    80.0    43.0    198.523828  \n",
      "year               2023.00  2023.0  2021.0      7.852801  \n",
      "month                 9.00    12.0     6.0     11.640129  \n",
      "day                  22.00    31.0    15.0     71.818050  \n",
      "hour                 19.00    23.0    16.0     16.920178  \n",
      "text_encoded        526.25   706.0   344.5  42371.050361  \n",
      "sentiment_encoded   201.00   278.0   139.0   5436.933647  \n",
      "timestamp_encoded   502.25   682.0   330.0  38154.007331  \n",
      "user_encoded        514.25   684.0   343.5  39193.986223  \n",
      "platform_encoded      2.00     3.0     1.0      1.090241  \n",
      "hashtags_encoded    523.25   696.0   351.5  40113.478346  \n",
      "country_encoded     100.00   114.0    63.5   1452.556682  \n",
      "Value counts for text:\n",
      "text\n",
      " A compassionate rain, tears of empathy falling gently, nurturing the seeds of kindness in the garden of human connections.     3\n",
      " Proudly scaling the peaks of achievement, a mountaineer conquering challenges and planting the flag of success.                3\n",
      " Embraced by the hopeful dawn, a gardener sowing seeds of optimism, tending to the blooms of a brighter tomorrow.               3\n",
      " A playful escapade in the carnival of life, carousel laughter and cotton candy dreams swirling in the joyous atmosphere.       3\n",
      " Bathed in the golden hues of gratefulness, a sunset of appreciation casting its warm glow on the landscapes of the heart.      2\n",
      "                                                                                                                               ..\n",
      "Collaborating on a science project that received recognition at a regional fair. Science triumphs and smiles!                   1\n",
      "Attending a surprise birthday party organized by friends. Surrounded by love, laughter, and good company!                       1\n",
      "Successfully fundraising for a school charity initiative. The joy of giving back to the community!                              1\n",
      "Participating in a multicultural festival, celebrating diversity with music, dance, and delicious food!                         1\n",
      "Organizing a virtual talent show during challenging times, bringing smiles to classmates' faces!                                1\n",
      "Name: count, Length: 707, dtype: int64\n",
      "\n",
      "Value counts for sentiment:\n",
      "sentiment\n",
      "Positive         44\n",
      "Joy              42\n",
      "Excitement       32\n",
      "Neutral          14\n",
      "Contentment      14\n",
      "                 ..\n",
      "Triumph           1\n",
      "Heartwarming      1\n",
      "Obstacle          1\n",
      "Sympathy          1\n",
      "Pressure          1\n",
      "Name: count, Length: 279, dtype: int64\n",
      "\n",
      "Value counts for timestamp:\n",
      "timestamp\n",
      "2020-01-05 08:45:00    3\n",
      "2022-07-17 06:15:00    3\n",
      "2018-08-22 17:20:00    3\n",
      "2021-07-01 12:10:00    3\n",
      "2019-04-05 17:30:00    3\n",
      "                      ..\n",
      "2016-09-14 12:30:00    1\n",
      "2017-08-18 18:20:00    1\n",
      "2018-06-22 14:15:00    1\n",
      "2020-02-29 20:45:00    1\n",
      "2023-01-20 11:30:00    1\n",
      "Name: count, Length: 683, dtype: int64\n",
      "\n",
      "Value counts for user:\n",
      "user\n",
      "RainNurturer                            3\n",
      "PeakConqueror                           3\n",
      "WindWhisperer                           3\n",
      "CarnivalDreamer                         3\n",
      "DawnGardener                            3\n",
      "                                       ..\n",
      "ScienceProjectSuccessHighSchool         1\n",
      "BirthdayPartyJoyHighSchool              1\n",
      "CharityFundraisingTriumphHighSchool     1\n",
      "MulticulturalFestivalJoyHighSchool      1\n",
      "User123                                 1\n",
      "Name: count, Length: 685, dtype: int64\n",
      "\n",
      "Value counts for platform:\n",
      "platform\n",
      "Instagram     258\n",
      "Facebook      231\n",
      "Twitter       128\n",
      "Twitter       115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for hashtags:\n",
      "hashtags\n",
      "#Compassionate #TearsOfEmpathy                 3\n",
      "#Proud #ScalingPeaks                           3\n",
      "#Hopeful #SeedsOfOptimism                      3\n",
      "#Playful #CarnivalEscapade                     3\n",
      "#Hopeful #SailorOfDreams                       2\n",
      "                                              ..\n",
      "#ScienceFairWinner #HighSchoolScience          1\n",
      "#SurpriseCelebration #HighSchoolFriendship     1\n",
      "#CommunityGiving #HighSchoolPhilanthropy       1\n",
      "#CulturalCelebration #HighSchoolUnity          1\n",
      "#CityExplore #HiddenGems                       1\n",
      "Name: count, Length: 697, dtype: int64\n",
      "\n",
      "Value counts for country:\n",
      "country\n",
      "USA           59\n",
      "USA           55\n",
      "UK            49\n",
      "Canada        44\n",
      "Australia     41\n",
      "              ..\n",
      "Ireland        1\n",
      "Scotland       1\n",
      "Kenya          1\n",
      "Jamaica        1\n",
      "Thailand       1\n",
      "Name: count, Length: 115, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number')\n",
    "\n",
    "# Summary statistics for numeric features\n",
    "numeric_summary = numeric_cols.describe().T  # Transpose for easier viewing\n",
    "\n",
    "# Add median and variance\n",
    "numeric_summary['median'] = numeric_cols.median()\n",
    "numeric_summary['variance'] = numeric_cols.var()\n",
    "\n",
    "print(numeric_summary)\n",
    "\n",
    "# Summary statistics for categorical features   \n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"Value counts for {col}:\\n{df[col].value_counts()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccde4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   text               732 non-null    object \n",
      " 1   sentiment          732 non-null    object \n",
      " 2   timestamp          732 non-null    object \n",
      " 3   user               732 non-null    object \n",
      " 4   platform           732 non-null    object \n",
      " 5   hashtags           732 non-null    object \n",
      " 6   retweets           732 non-null    float64\n",
      " 7   likes              732 non-null    float64\n",
      " 8   country            732 non-null    object \n",
      " 9   year               732 non-null    int64  \n",
      " 10  month              732 non-null    int64  \n",
      " 11  day                732 non-null    int64  \n",
      " 12  hour               732 non-null    int64  \n",
      " 13  text_encoded       732 non-null    int64  \n",
      " 14  sentiment_encoded  732 non-null    int64  \n",
      " 15  timestamp_encoded  732 non-null    int64  \n",
      " 16  user_encoded       732 non-null    int64  \n",
      " 17  platform_encoded   732 non-null    int64  \n",
      " 18  hashtags_encoded   732 non-null    int64  \n",
      " 19  country_encoded    732 non-null    int64  \n",
      "dtypes: float64(2), int64(11), object(7)\n",
      "memory usage: 114.5+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "                                                text    sentiment  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
      "1   Traffic was terrible this morning.           ...   Negative     \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
      "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
      "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
      "\n",
      "             timestamp            user     platform  \\\n",
      "0  2023-01-15 12:30:00   User123          Twitter     \n",
      "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
      "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
      "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
      "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
      "\n",
      "                                     hashtags  retweets  likes       country  \\\n",
      "0   #Nature #Park                                  15.0   30.0     USA         \n",
      "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
      "2   #Fitness #Workout                              20.0   40.0   USA           \n",
      "3   #Travel #Adventure                              8.0   15.0     UK          \n",
      "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
      "\n",
      "   year  month  day  hour  text_encoded  sentiment_encoded  timestamp_encoded  \\\n",
      "0  2023      1   15    12           105                214                401   \n",
      "1  2023      1   15     8           293                195                400   \n",
      "2  2023      1   15    15           191                214                402   \n",
      "3  2023      1   15    18           120                214                403   \n",
      "4  2023      1   15    19           296                197                405   \n",
      "\n",
      "   user_encoded  platform_encoded  hashtags_encoded  country_encoded  \n",
      "0           645                 3               491              106  \n",
      "1           118                 3               674               20  \n",
      "2           226                 1               309              108  \n",
      "3             7                 0               677               91  \n",
      "4            90                 1               158                0  \n",
      "\n",
      "Summary Statistics:\n",
      "         retweets       likes         year       month         day  \\\n",
      "count  732.000000  732.000000   732.000000  732.000000  732.000000   \n",
      "mean    21.508197   42.901639  2020.471311    6.122951   15.497268   \n",
      "std      7.061286   14.089848     2.802285    3.411763    8.474553   \n",
      "min      5.000000   10.000000  2010.000000    1.000000    1.000000   \n",
      "25%     17.750000   34.750000  2019.000000    3.000000    9.000000   \n",
      "50%     22.000000   43.000000  2021.000000    6.000000   15.000000   \n",
      "75%     25.000000   50.000000  2023.000000    9.000000   22.000000   \n",
      "max     40.000000   80.000000  2023.000000   12.000000   31.000000   \n",
      "\n",
      "             hour  text_encoded  sentiment_encoded  timestamp_encoded  \\\n",
      "count  732.000000    732.000000         732.000000         732.000000   \n",
      "mean    15.521858    348.054645         138.405738         334.312842   \n",
      "std      4.113414    205.842295          73.735566         195.330508   \n",
      "min      0.000000      0.000000           0.000000           0.000000   \n",
      "25%     13.000000    170.750000          78.000000         167.750000   \n",
      "50%     16.000000    344.500000         139.000000         330.000000   \n",
      "75%     19.000000    526.250000         201.000000         502.250000   \n",
      "max     23.000000    706.000000         278.000000         682.000000   \n",
      "\n",
      "       user_encoded  platform_encoded  hashtags_encoded  country_encoded  \n",
      "count    732.000000        732.000000        732.000000       732.000000  \n",
      "mean     343.538251          1.173497        349.203552        61.122951  \n",
      "std      197.974711          1.044146        200.283495        38.112422  \n",
      "min        0.000000          0.000000          0.000000         0.000000  \n",
      "25%      171.000000          0.000000        174.750000        20.750000  \n",
      "50%      343.500000          1.000000        351.500000        63.500000  \n",
      "75%      514.250000          2.000000        523.250000       100.000000  \n",
      "max      684.000000          3.000000        696.000000       114.000000  \n",
      "\n",
      "Numeric Summary:\n",
      "                   count         mean         std     min      25%     50%  \\\n",
      "retweets           732.0    21.508197    7.061286     5.0    17.75    22.0   \n",
      "likes              732.0    42.901639   14.089848    10.0    34.75    43.0   \n",
      "year               732.0  2020.471311    2.802285  2010.0  2019.00  2021.0   \n",
      "month              732.0     6.122951    3.411763     1.0     3.00     6.0   \n",
      "day                732.0    15.497268    8.474553     1.0     9.00    15.0   \n",
      "hour               732.0    15.521858    4.113414     0.0    13.00    16.0   \n",
      "text_encoded       732.0   348.054645  205.842295     0.0   170.75   344.5   \n",
      "sentiment_encoded  732.0   138.405738   73.735566     0.0    78.00   139.0   \n",
      "timestamp_encoded  732.0   334.312842  195.330508     0.0   167.75   330.0   \n",
      "user_encoded       732.0   343.538251  197.974711     0.0   171.00   343.5   \n",
      "platform_encoded   732.0     1.173497    1.044146     0.0     0.00     1.0   \n",
      "hashtags_encoded   732.0   349.203552  200.283495     0.0   174.75   351.5   \n",
      "country_encoded    732.0    61.122951   38.112422     0.0    20.75    63.5   \n",
      "\n",
      "                       75%     max  median      variance  skewness  missing  \n",
      "retweets             25.00    40.0    22.0     49.861766  0.363412        0  \n",
      "likes                50.00    80.0    43.0    198.523828  0.378139        0  \n",
      "year               2023.00  2023.0  2021.0      7.852801 -1.029292        0  \n",
      "month                 9.00    12.0     6.0     11.640129 -0.002967        0  \n",
      "day                  22.00    31.0    15.0     71.818050  0.039915        0  \n",
      "hour                 19.00    23.0    16.0     16.920178 -0.436003        0  \n",
      "text_encoded        526.25   706.0   344.5  42371.050361  0.026575        0  \n",
      "sentiment_encoded   201.00   278.0   139.0   5436.933647 -0.080375        0  \n",
      "timestamp_encoded   502.25   682.0   330.0  38154.007331  0.057425        0  \n",
      "user_encoded        514.25   684.0   343.5  39193.986223  0.000503        0  \n",
      "platform_encoded      2.00     3.0     1.0      1.090241  0.480028        0  \n",
      "hashtags_encoded    523.25   696.0   351.5  40113.478346 -0.011315        0  \n",
      "country_encoded     100.00   114.0    63.5   1452.556682 -0.228216        0  \n",
      "\n",
      "Value counts for text:\n",
      "text\n",
      " A compassionate rain, tears of empathy falling gently, nurturing the seeds of kindness in the garden of human connections.     3\n",
      " Proudly scaling the peaks of achievement, a mountaineer conquering challenges and planting the flag of success.                3\n",
      " Embraced by the hopeful dawn, a gardener sowing seeds of optimism, tending to the blooms of a brighter tomorrow.               3\n",
      " A playful escapade in the carnival of life, carousel laughter and cotton candy dreams swirling in the joyous atmosphere.       3\n",
      " Bathed in the golden hues of gratefulness, a sunset of appreciation casting its warm glow on the landscapes of the heart.      2\n",
      "                                                                                                                               ..\n",
      "Collaborating on a science project that received recognition at a regional fair. Science triumphs and smiles!                   1\n",
      "Attending a surprise birthday party organized by friends. Surrounded by love, laughter, and good company!                       1\n",
      "Successfully fundraising for a school charity initiative. The joy of giving back to the community!                              1\n",
      "Participating in a multicultural festival, celebrating diversity with music, dance, and delicious food!                         1\n",
      "Organizing a virtual talent show during challenging times, bringing smiles to classmates' faces!                                1\n",
      "Name: count, Length: 707, dtype: int64\n",
      "\n",
      "Value counts for sentiment:\n",
      "sentiment\n",
      "Positive         44\n",
      "Joy              42\n",
      "Excitement       32\n",
      "Neutral          14\n",
      "Contentment      14\n",
      "                 ..\n",
      "Triumph           1\n",
      "Heartwarming      1\n",
      "Obstacle          1\n",
      "Sympathy          1\n",
      "Pressure          1\n",
      "Name: count, Length: 279, dtype: int64\n",
      "\n",
      "Value counts for timestamp:\n",
      "timestamp\n",
      "2020-01-05 08:45:00    3\n",
      "2022-07-17 06:15:00    3\n",
      "2018-08-22 17:20:00    3\n",
      "2021-07-01 12:10:00    3\n",
      "2019-04-05 17:30:00    3\n",
      "                      ..\n",
      "2016-09-14 12:30:00    1\n",
      "2017-08-18 18:20:00    1\n",
      "2018-06-22 14:15:00    1\n",
      "2020-02-29 20:45:00    1\n",
      "2023-01-20 11:30:00    1\n",
      "Name: count, Length: 683, dtype: int64\n",
      "\n",
      "Value counts for user:\n",
      "user\n",
      "RainNurturer                            3\n",
      "PeakConqueror                           3\n",
      "WindWhisperer                           3\n",
      "CarnivalDreamer                         3\n",
      "DawnGardener                            3\n",
      "                                       ..\n",
      "ScienceProjectSuccessHighSchool         1\n",
      "BirthdayPartyJoyHighSchool              1\n",
      "CharityFundraisingTriumphHighSchool     1\n",
      "MulticulturalFestivalJoyHighSchool      1\n",
      "User123                                 1\n",
      "Name: count, Length: 685, dtype: int64\n",
      "\n",
      "Value counts for platform:\n",
      "platform\n",
      "Instagram     258\n",
      "Facebook      231\n",
      "Twitter       128\n",
      "Twitter       115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for hashtags:\n",
      "hashtags\n",
      "#Compassionate #TearsOfEmpathy                 3\n",
      "#Proud #ScalingPeaks                           3\n",
      "#Hopeful #SeedsOfOptimism                      3\n",
      "#Playful #CarnivalEscapade                     3\n",
      "#Hopeful #SailorOfDreams                       2\n",
      "                                              ..\n",
      "#ScienceFairWinner #HighSchoolScience          1\n",
      "#SurpriseCelebration #HighSchoolFriendship     1\n",
      "#CommunityGiving #HighSchoolPhilanthropy       1\n",
      "#CulturalCelebration #HighSchoolUnity          1\n",
      "#CityExplore #HiddenGems                       1\n",
      "Name: count, Length: 697, dtype: int64\n",
      "\n",
      "Value counts for country:\n",
      "country\n",
      "USA           59\n",
      "USA           55\n",
      "UK            49\n",
      "Canada        44\n",
      "Australia     41\n",
      "              ..\n",
      "Ireland        1\n",
      "Scotland       1\n",
      "Kenya          1\n",
      "Jamaica        1\n",
      "Thailand       1\n",
      "Name: count, Length: 115, dtype: int64\n",
      "\n",
      "EDA complete! All outputs saved in 'EDA_Outputs' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Step 0: Setup\n",
    "# -----------------------------\n",
    "output_dir = 'EDA_Outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Note: df is already loaded from a previous cell\n",
    "\n",
    "# Quick overview\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Summary Statistics\n",
    "# -----------------------------\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "numeric_summary = df[numeric_cols].describe().T\n",
    "numeric_summary['median'] = df[numeric_cols].median()\n",
    "numeric_summary['variance'] = df[numeric_cols].var()\n",
    "numeric_summary['skewness'] = df[numeric_cols].skew()\n",
    "numeric_summary['missing'] = df[numeric_cols].isnull().sum()\n",
    "numeric_summary.to_csv(os.path.join(output_dir, 'numeric_summary.csv'))\n",
    "\n",
    "print(\"\\nNumeric Summary:\")\n",
    "print(numeric_summary)\n",
    "\n",
    "# Categorical counts\n",
    "cat_counts = {}\n",
    "for col in categorical_cols:\n",
    "    counts = df[col].value_counts()\n",
    "    cat_counts[col] = counts\n",
    "    counts.to_csv(os.path.join(output_dir, f'{col}_value_counts.csv'))\n",
    "    print(f\"\\nValue counts for {col}:\\n{counts}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Visualizations\n",
    "# -----------------------------\n",
    "# Histograms\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.savefig(os.path.join(output_dir, f'hist_{col}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Boxplots\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.savefig(os.path.join(output_dir, f'box_{col}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Scatter plots (pairwise for first 5 numeric columns, adjust as needed)\n",
    "pair_cols = numeric_cols[:5]  # first 5 numeric columns\n",
    "for i in range(len(pair_cols)):\n",
    "    for j in range(i+1, len(pair_cols)):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.scatterplot(x=df[pair_cols[i]], y=df[pair_cols[j]])\n",
    "        plt.title(f'{pair_cols[i]} vs {pair_cols[j]}')\n",
    "        plt.savefig(os.path.join(output_dir, f'scatter_{pair_cols[i]}_vs_{pair_cols[j]}.png'))\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Correlation Analysis\n",
    "# -----------------------------\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.savefig(os.path.join(output_dir, 'correlation_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Top correlations\n",
    "high_corr = corr_matrix.unstack().sort_values(ascending=False)\n",
    "high_corr = high_corr[high_corr < 1].drop_duplicates()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Insights Report\n",
    "# -----------------------------\n",
    "insights = []\n",
    "\n",
    "# Numeric insights\n",
    "for col in numeric_cols:\n",
    "    skew_flag = \" (High Skew!)\" if abs(df[col].skew()) > 1 else \"\"\n",
    "    outliers = df[col][(df[col] < df[col].quantile(0.01)) | (df[col] > df[col].quantile(0.99))]\n",
    "    outlier_flag = f\" ({len(outliers)} potential outliers)\" if len(outliers) > 0 else \"\"\n",
    "    insights.append(f\"{col} - Mean: {df[col].mean():.2f}, Median: {df[col].median():.2f}, Variance: {df[col].var():.2f}, Skewness: {df[col].skew():.2f}{skew_flag}{outlier_flag}\")\n",
    "\n",
    "# Top correlations\n",
    "insights.append(\"\\nTop 5 correlations (excluding 1.0):\")\n",
    "insights.extend([f\"{idx[0]} & {idx[1]}: {val:.2f}\" for idx, val in high_corr.head(5).items()])\n",
    "\n",
    "# Categorical insights\n",
    "insights.append(\"\\nCategorical Columns Insights:\")\n",
    "for col in categorical_cols:\n",
    "    top_cat = df[col].value_counts().idxmax()\n",
    "    top_freq = df[col].value_counts().max()\n",
    "    insights.append(f\"{col} - Most frequent: {top_cat} ({top_freq} occurrences)\")\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(output_dir, 'EDA_Report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    for line in insights:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"\\nEDA complete! All outputs saved in '{output_dir}' folder.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
